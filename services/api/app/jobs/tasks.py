"""
Celery Task Definitions

Organized by domain to match BullMQ queue structure.
Each task includes:
- Proper queue routing
- Retry configuration
- Logging
- Error handling

Tasks are grouped by:
- Email: Transactional and notification emails
- Notification: In-app and push notifications
- Certificate: Generation and eligibility checks
- Report: Data exports and scheduled reports
- Import: Bulk user/data imports
- Gamification: Points, badges, levels
- Timeline: Activity feed events
- Automation: Rule-based automation execution
"""

import asyncio
from typing import Any, Dict, List, Optional

from app.db.models import NotificationHistory, PointsLedger, TimelineEvent
from app.db.session import get_db_context
from celery import shared_task  # type: ignore
from celery.utils.log import get_task_logger  # type: ignore

logger = get_task_logger(__name__)


def run_async(coro):
    """Run an async coroutine in a synchronous context."""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)


# ============= Email Tasks =============


@shared_task(
    bind=True,
    name="app.jobs.tasks.send_email",
    queue="email",
    max_retries=3,
    default_retry_delay=5,
    autoretry_for=(Exception,),
    retry_backoff=True,
    retry_backoff_max=600,
)
def send_email(
    self,
    email_type: str,
    to: str,
    subject: str,
    tenant_id: str,
    template_data: Optional[Dict[str, Any]] = None,
    template_id: Optional[str] = None,
    user_id: Optional[str] = None,
):
    """
    Send an email using a template.

    Args:
        email_type: Type of email (welcome, password_reset, notification, etc.)
        to: Recipient email address
        subject: Email subject
        tenant_id: Tenant ID for template customization
        template_data: Data to populate template
        template_id: Optional custom template ID
        user_id: Optional user ID for tracking
    """
    logger.info(
        f"[EMAIL] Sending {email_type} to {to}",
        extra={
            "email_type": email_type,
            "to": to,
            "tenant_id": tenant_id,
            "attempt": self.request.retries + 1,
        },
    )

    try:
        # TODO: Integrate with actual email service (SendGrid, SES, etc.)
        # For now, just simulate success

        if email_type == "welcome":
            logger.info(f"[EMAIL] Welcome email to {to}")
        elif email_type == "password_reset":
            logger.info(f"[EMAIL] Password reset email to {to}")
        elif email_type == "notification":
            logger.info(f"[EMAIL] Notification email to {to}: {subject}")
        elif email_type == "certificate_ready":
            logger.info(f"[EMAIL] Certificate ready email to {to}")
        elif email_type == "enrollment":
            logger.info(f"[EMAIL] Enrollment confirmation to {to}")

        return {
            "success": True,
            "type": email_type,
            "to": to,
            "tenant_id": tenant_id,
        }

    except Exception as exc:
        logger.exception(f"[EMAIL] Failed to send {email_type} to {to}")
        raise self.retry(exc=exc)


@shared_task(
    name="app.jobs.tasks.send_bulk_email",
    queue="email",
    max_retries=2,
)
def send_bulk_email(
    recipients: List[str],
    subject: str,
    template_id: str,
    template_data: Dict[str, Any],
    tenant_id: str,
):
    """Send bulk email to multiple recipients."""
    logger.info(f"[EMAIL] Sending bulk email to {len(recipients)} recipients")

    results = []
    for recipient in recipients:
        # Queue individual emails for better retry handling
        result = send_email.delay(
            email_type="notification",
            to=recipient,
            subject=subject,
            tenant_id=tenant_id,
            template_data=template_data,
            template_id=template_id,
        )
        results.append({"to": recipient, "task_id": result.id})

    return {"queued": len(results), "results": results}


# ============= Notification Tasks =============


@shared_task(
    bind=True,
    name="app.jobs.tasks.notify_user",
    queue="notification",
    max_retries=3,
    default_retry_delay=3,
)
def notify_user(
    self,
    notification_type: str,
    recipient_id: str,
    tenant_id: str,
    title: str,
    body: str,
    link: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
):
    """
    Create an in-app notification for a user.
    """
    logger.info(f"[NOTIFICATION] {notification_type} to {recipient_id}: {title}")

    async def _impl():
        async with get_db_context() as db:
            # Create notification history record
            history = NotificationHistory(
                user_id=recipient_id,
                tenant_id=tenant_id,
                channel=notification_type.upper(),
                status="SENT",
                metadata={
                    "title": title,
                    "body": body,
                    "link": link,
                    **(metadata or {}),
                },
            )
            db.add(history)
            # If type is push, we would also call external service here
            await db.commit()
            return history.id

    try:
        history_id = run_async(_impl())

        return {
            "success": True,
            "type": notification_type,
            "recipient_id": recipient_id,
            "title": title,
            "history_id": history_id,
        }

    except Exception as exc:
        logger.exception(f"[NOTIFICATION] Failed to notify {recipient_id}")
        raise self.retry(exc=exc)


@shared_task(
    name="app.jobs.tasks.notify_batch",
    queue="notification",
)
def notify_batch(notifications: List[Dict[str, Any]]):
    """Send batch notifications."""
    results = []
    for notif in notifications:
        result = notify_user.delay(**notif)
        results.append(result.id)
    return {"queued": len(results)}


# ============= Certificate Tasks =============


@shared_task(
    bind=True,
    name="app.jobs.tasks.certificate_check_eligibility",
    queue="certificate",
    max_retries=3,
)
def certificate_check_eligibility(
    self,
    user_id: str,
    course_id: str,
    tenant_id: str,
):
    """
    Check if user is eligible for a certificate.

    If eligible, queues PDF generation.
    """
    logger.info(
        f"[CERTIFICATE] Checking eligibility for user={user_id} course={course_id}"
    )

    try:
        # TODO: Query enrollment status and completion
        # TODO: Check certificate template exists for course

        is_eligible = False  # Placeholder

        if is_eligible:
            logger.info(f"[CERTIFICATE] User {user_id} eligible for certificate")
            # Queue PDF generation
            # certificate_generate_pdf.delay(...)

        return {
            "eligible": is_eligible,
            "user_id": user_id,
            "course_id": course_id,
        }

    except Exception as exc:
        logger.exception("[CERTIFICATE] Eligibility check failed")
        raise self.retry(exc=exc)


@shared_task(
    bind=True,
    name="app.jobs.tasks.certificate_generate_pdf",
    queue="certificate",
    max_retries=3,
    time_limit=120,  # 2 minute limit for PDF generation
)
def certificate_generate_pdf(
    self,
    certificate_issue_id: str,
    tenant_id: str,
    user_id: str,
):
    """
    Generate PDF certificate.

    Uses the certificate template and user data to generate PDF.
    """
    logger.info(f"[CERTIFICATE] Generating PDF for issue={certificate_issue_id}")

    try:
        # TODO: Fetch certificate issue record
        # TODO: Load template
        # TODO: Generate PDF (WeasyPrint, Puppeteer, etc.)
        # TODO: Upload to S3
        # TODO: Update certificate issue with PDF URL

        return {
            "success": True,
            "certificate_issue_id": certificate_issue_id,
            "pdf_url": None,  # TODO: Return actual URL
        }

    except Exception as exc:
        logger.exception("[CERTIFICATE] PDF generation failed")
        raise self.retry(exc=exc)


# ============= Import Tasks =============


@shared_task(
    bind=True,
    name="app.jobs.tasks.import_users",
    queue="import",
    max_retries=1,  # Imports should not auto-retry
    time_limit=1800,  # 30 minute limit for large imports
)
def import_users(
    self,
    import_job_id: str,
    file_path: str,
    tenant_id: str,
    user_id: str,
    options: Optional[Dict[str, Any]] = None,
):
    """
    Process bulk user import from CSV.

    Args:
        import_job_id: ID of the ImportJob record
        file_path: Path to uploaded CSV file
        tenant_id: Tenant ID
        user_id: User who initiated import
        options: Import options (skip_existing, update_existing, etc.)
    """
    logger.info(f"[IMPORT] Processing user import job={import_job_id}")

    options = options or {}
    success_count = 0
    failure_count = 0
    errors: list[str] = []

    try:
        # TODO: Update job status to PROCESSING
        # TODO: Read and parse CSV file
        # TODO: Validate each row
        # TODO: Insert/update users
        # TODO: Update job status to COMPLETED/PARTIAL/FAILED

        return {
            "success": True,
            "import_job_id": import_job_id,
            "processed": success_count + failure_count,
            "success_count": success_count,
            "failure_count": failure_count,
            "errors": errors,
        }

    except Exception:
        logger.exception(f"[IMPORT] Import job {import_job_id} failed")
        # TODO: Update job status to FAILED
        raise


@shared_task(
    name="app.jobs.tasks.import_enrollments",
    queue="import",
    max_retries=1,
    time_limit=1800,
)
def import_enrollments(
    import_job_id: str,
    file_path: str,
    tenant_id: str,
    user_id: str,
    options: Optional[Dict[str, Any]] = None,
):
    """Process bulk enrollment import from CSV."""
    logger.info(f"[IMPORT] Processing enrollment import job={import_job_id}")

    # TODO: Similar to import_users

    return {"success": True, "import_job_id": import_job_id}


@shared_task(
    name="app.jobs.tasks.users_import",
    queue="import",
)
def users_import(
    tenant_id: str,
    file_id: str,
    options: Optional[Dict[str, Any]] = None,
    requester_id: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Compatibility wrapper for Next.js 'users import' job.
    Creates a logical import job and delegates to import_users.
    """
    logger.info(
        f"[IMPORT] users_import file_id={file_id} tenant={tenant_id} requester={requester_id}"
    )
    import_job_id = f"imp-{file_id}"
    # In a real system, file_id would be resolved to a storage path
    file_path = f"/tmp/uploads/{file_id}.csv"
    # Fire the heavy task
    result = import_users.delay(
        import_job_id=import_job_id,
        file_path=file_path,
        tenant_id=tenant_id,
        user_id=requester_id or "",
        options=options or {},
    )
    return {"queued": True, "taskId": result.id, "importJobId": import_job_id}


# ============= Gamification Tasks =============


@shared_task(
    name="app.jobs.tasks.gamification_award_points",
    queue="gamification",
    max_retries=3,
)
def gamification_award_points(
    user_id: str,
    tenant_id: str,
    action: str,
    points: int,
    metadata: Optional[Dict[str, Any]] = None,
):
    """
    Award points to a user.
    """
    logger.info(f"[GAMIFICATION] Awarding {points} points to {user_id} for {action}")

    async def _impl():
        async with get_db_context() as db:
            ledger = PointsLedger(user_id=user_id, points=points, reason=action)
            db.add(ledger)
            await db.commit()
            return ledger.id

    try:
        ledger_id = run_async(_impl())

        # Queue badge check
        gamification_check_badges.delay(user_id, tenant_id)

        return {
            "success": True,
            "user_id": user_id,
            "points": points,
            "action": action,
            "ledger_id": ledger_id,
        }

    except Exception:
        logger.exception("[GAMIFICATION] Failed to award points")
        raise


@shared_task(
    name="app.jobs.tasks.gamification_check_badges",
    queue="gamification",
    max_retries=3,
)
def gamification_check_badges(user_id: str, tenant_id: str):
    """Check and award badges based on user's achievements."""
    logger.info(f"[GAMIFICATION] Checking badges for {user_id}")

    try:
        # TODO: Query user's total points
        # TODO: Query badge thresholds
        # TODO: Award any newly qualified badges

        return {
            "success": True,
            "user_id": user_id,
            "badges_awarded": [],
        }

    except Exception:
        logger.exception("[GAMIFICATION] Badge check failed")
        raise


@shared_task(
    name="app.jobs.tasks.gamification_recalculate",
    queue="gamification",
)
def gamification_recalculate(user_id: str, tenant_id: str):
    """Recalculate all gamification data for a user."""
    logger.info(f"[GAMIFICATION] Recalculating for {user_id}")

    # TODO: Recalculate total points
    # TODO: Recheck all badge eligibility
    # TODO: Update user level

    return {"success": True, "user_id": user_id}


# ============= Timeline Tasks =============


@shared_task(
    name="app.jobs.tasks.timeline_add_event",
    queue="timeline",
    max_retries=2,
)
def timeline_add_event(
    user_id: str,
    tenant_id: str,
    event_type: str,
    course_id: Optional[str] = None,
    enrollment_id: Optional[str] = None,
    details: Optional[Dict[str, Any]] = None,
):
    """
    Add an event to user's timeline.
    """
    if not tenant_id:
        logger.warning(f"[TIMELINE] Skipping event {event_type} - missing tenant_id")
        return {"success": False, "reason": "Missing tenant_id"}

    logger.info(f"[TIMELINE] Adding {event_type} for {user_id}")

    async def _impl():
        async with get_db_context() as db:
            event = TimelineEvent(
                user_id=user_id,
                tenant_id=tenant_id,
                event_type=event_type,
                course_id=course_id,
                branch_id=details.get("branchId") if details else None,
                details={**(details or {}), "enrollmentId": enrollment_id},
            )
            db.add(event)
            await db.commit()
            return event.id

    try:
        event_id = run_async(_impl())

        return {
            "success": True,
            "user_id": user_id,
            "event_type": event_type,
            "event_id": event_id,
        }

    except Exception:
        logger.exception("[TIMELINE] Failed to add event")
        raise


# ============= Report Tasks =============


@shared_task(
    bind=True,
    name="app.jobs.tasks.report_generate",
    queue="report",
    max_retries=2,
    time_limit=600,  # 10 minute limit
)
def report_generate(
    self,
    report_id: str,
    tenant_id: str,
    user_id: str,
    format: str = "xlsx",
    filters: Optional[Dict[str, Any]] = None,
    recipients: Optional[List[str]] = None,
):
    """
    Generate a report.

    Args:
        report_id: Report definition ID
        tenant_id: Tenant ID
        user_id: User requesting report
        format: Output format (csv, xlsx, pdf)
        filters: Report filters
        recipients: Email recipients for scheduled reports
    """
    logger.info(f"[REPORT] Generating report={report_id} as {format}")

    try:
        # TODO: Load report definition
        # TODO: Execute query with filters
        # TODO: Format output
        # TODO: Save to S3
        # TODO: Email recipients if specified

        return {
            "success": True,
            "report_id": report_id,
            "format": format,
            "download_url": None,  # TODO: Return actual URL
        }

    except Exception as exc:
        logger.exception("[REPORT] Report generation failed")
        raise self.retry(exc=exc, countdown=30)


@shared_task(
    name="app.jobs.tasks.report_export",
    queue="report",
    max_retries=2,
)
def report_export(
    report_id: str,
    tenant_id: str,
    user_id: str,
    format: str = "xlsx",
):
    """Export a saved report to file."""
    return report_generate(
        report_id=report_id,
        tenant_id=tenant_id,
        user_id=user_id,
        format=format,
    )


# ============= Automation Tasks =============


@shared_task(
    bind=True,
    name="app.jobs.tasks.automation_evaluate",
    queue="automation",
    max_retries=2,
)
def automation_evaluate(
    self,
    automation_id: str,
    tenant_id: str,
    trigger_id: Optional[str] = None,
    user_id: Optional[str] = None,
):
    """
    Evaluate an automation rule.

    Checks if conditions are met and queues execution if so.
    """
    logger.info(f"[AUTOMATION] Evaluating automation={automation_id}")

    try:
        # TODO: Load automation definition
        # TODO: Check trigger conditions
        # TODO: If conditions met, queue execution

        should_execute = False  # Placeholder

        if should_execute:
            automation_execute.delay(
                automation_id=automation_id,
                tenant_id=tenant_id,
                user_id=user_id,
            )

        return {
            "success": True,
            "automation_id": automation_id,
            "executed": should_execute,
        }

    except Exception as exc:
        logger.exception("[AUTOMATION] Evaluation failed")
        raise self.retry(exc=exc)


@shared_task(
    bind=True,
    name="app.jobs.tasks.automation_execute",
    queue="automation",
    max_retries=2,
)
def automation_execute(
    self,
    automation_id: str,
    tenant_id: str,
    user_id: Optional[str] = None,
    action: Optional[str] = None,
):
    """
    Execute an automation action.

    Performs the configured action (send email, enroll user, etc.)
    """
    logger.info(f"[AUTOMATION] Executing automation={automation_id}")

    try:
        # TODO: Load automation definition
        # TODO: Execute configured action
        # TODO: Log execution result

        return {
            "success": True,
            "automation_id": automation_id,
            "action_taken": action,
        }

    except Exception as exc:
        logger.exception("[AUTOMATION] Execution failed")
        raise self.retry(exc=exc)
